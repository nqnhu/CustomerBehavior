{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count, lit, row_number\n",
    "import pyspark.sql.functions as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"7g\").config('spark.jars.packages','mysql:mysql-connector-java:8.0.17').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_miss_value(df):\n",
    "     miss_value = df.withColumn('Missing Value',\n",
    "                        when(col('Contract').contains('None') | col('Contract').contains('NULL') | (col('Contract') == '' ) | col('Contract').isNull() | isnan('Contract') | \n",
    "                             col('AppName').contains('None') | col('AppName').contains('NULL') | (col('AppName') == '' ) | col('AppName').isNull() | isnan('AppName') |\n",
    "                             col('TotalDuration').contains('None') | col('TotalDuration').contains('NULL') | (col('TotalDuration') == '' ) | col('TotalDuration').isNull() | isnan('TotalDuration'), 'True')\n",
    "                        .otherwise('False'))\n",
    "   \n",
    "     df_miss_value = miss_value.where(col(\"Missing Value\") == 'True').select('Contract', 'AppName', 'TotalDuration')\n",
    "     if df_miss_value.count() > 0:\n",
    "        df = df.exceptAll(df_miss_value)\n",
    "     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, file_name):\n",
    "    df = spark.read.json(path + file_name)\n",
    "    df = df.select('_source.*')\n",
    "    df = df.select('Contract', 'AppName', 'TotalDuration')\n",
    "    df = check_miss_value(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_1_day(path, file_name):\n",
    "    df = read_data(path, file_name)\n",
    "    df = df.withColumn('Category',\n",
    "                       when((col('AppName') == 'KPLUS') | (col('AppName') == 'CHANNEL'), 'Truyền Hình')\n",
    "                      .when((col('AppName') == 'VOD') | (col('AppName') == 'FIMS') | (col('AppName') == 'BHD'), 'Phim Truyện')\n",
    "                      .when((col('AppName') == 'RELAX'), 'Giải Trí')\n",
    "                      .when((col('AppName') == 'CHILD'), 'Thiếu Nhi')\n",
    "                      .when((col('AppName') == 'SPORT'), 'Thể Thao')\n",
    "                      .otherwise('Error'))\n",
    "    \n",
    "    date_of_file = (file_name[:4] + '-' + file_name[4:6] + '-' + file_name[6:]).replace('.json', '')\n",
    "    df = df.withColumn('Date', lit(date_of_file))\n",
    "    \n",
    "    df = df.select('Contract', 'Date', 'Category', 'TotalDuration')\n",
    "    df = df.filter(df.Category != 'Error')    \n",
    "\n",
    "    df = df.groupBy('Contract', 'Date', 'Category').sum()\n",
    "    df = df.withColumnRenamed('sum(TotalDuration)', 'TotalDuration')\n",
    "\n",
    "    # ------ CHECK OUTLIER ------\n",
    "    df = df.filter((df['TotalDuration'] >= 0) & (df['TotalDuration'] <= 86400))\n",
    "\n",
    "    print('Finished Processing {}'.format(file_name))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_to_mysql(data, table_name):\n",
    "    url = 'jdbc:mysql://' + 'localhost' + ':' + '3306' + '/' + 'customer_360_platform'\n",
    "    driver = \"com.mysql.cj.jdbc.Driver\"\n",
    "    user = 'root'\n",
    "    password = ''\n",
    "    data.write.format('jdbc').option('url', url).option('driver', driver).option('dbtable', table_name).option('user', user).option('password', password).mode('append').save()\n",
    "    return print('Data imported successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_task():\n",
    "    path = \"C:\\\\Users\\\\NKNhu\\\\LearnBigData\\\\Dataset\\\\log_content\\\\\"\n",
    "    list_file = os.listdir(path)\n",
    "    file_name1 = list_file[0]\n",
    "    df = etl_1_day(path, file_name1)\n",
    "    for i in list_file[1:]:\n",
    "        file_name2 = i \n",
    "        df_ = etl_1_day(path ,file_name2)\n",
    "        df = df.union(df_)\n",
    "        df = df.cache()\n",
    "    \n",
    "    df = df.groupBy('Contract', 'Date').pivot('Category').sum('TotalDuration')\n",
    "    df = df.withColumnRenamed('Truyền Hình', 'TV_Duration') \\\n",
    "                        .withColumnRenamed('Phim Truyện', 'Movie_Duration') \\\n",
    "                            .withColumnRenamed('Thiếu Nhi', 'Child_Duration') \\\n",
    "                                .withColumnRenamed('Thể Thao', 'Sport_Duration') \\\n",
    "                                    .withColumnRenamed('Giải Trí', 'Relax_Duration')\n",
    "    \n",
    "    print('-----------Saving Data ---------')\n",
    "    import_data_to_mysql(data = df, table_name = 'data_behavior_daily_')\n",
    "    df.repartition(1).write.csv('C:\\\\Users\\\\NKNhu\\\\Project\\\\Customer_Behavior\\\\DF_ETL_CLEAN_', header=True)\n",
    "    print('Data Saved Successfully.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Processing 20220401.json\n",
      "Finished Processing 20220402.json\n",
      "Finished Processing 20220403.json\n",
      "Finished Processing 20220404.json\n",
      "Finished Processing 20220405.json\n",
      "Finished Processing 20220406.json\n",
      "Finished Processing 20220407.json\n",
      "Finished Processing 20220408.json\n",
      "Finished Processing 20220409.json\n",
      "Finished Processing 20220410.json\n",
      "Finished Processing 20220411.json\n",
      "Finished Processing 20220412.json\n",
      "Finished Processing 20220413.json\n",
      "Finished Processing 20220414.json\n",
      "Finished Processing 20220415.json\n",
      "Finished Processing 20220416.json\n",
      "Finished Processing 20220417.json\n",
      "Finished Processing 20220418.json\n",
      "Finished Processing 20220419.json\n",
      "Finished Processing 20220420.json\n",
      "Finished Processing 20220421.json\n",
      "Finished Processing 20220422.json\n",
      "Finished Processing 20220423.json\n",
      "Finished Processing 20220424.json\n",
      "Finished Processing 20220425.json\n",
      "Finished Processing 20220426.json\n",
      "Finished Processing 20220427.json\n",
      "Finished Processing 20220428.json\n",
      "Finished Processing 20220429.json\n",
      "Finished Processing 20220430.json\n",
      "-----------Saving Data ---------\n",
      "Data imported successfully.\n",
      "Data Saved Successfully.\n"
     ]
    }
   ],
   "source": [
    "df = main_task()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
